# -*- coding: utf-8 -*-
"""
DirectTaskExecutor: 合并 Analyzer + Planner 的功能
并行评估 MCP 和 ComputerUse 可行性（两个独立 LLM 调用）
优先使用 MCP，其次使用 ComputerUse
"""
import json
import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from openai import AsyncOpenAI, APIConnectionError, InternalServerError, RateLimitError
import httpx
from config import MODELS_WITH_EXTRA_BODY, USER_PLUGIN_SERVER_PORT
from utils.config_manager import get_config_manager
from .mcp_client import McpRouterClient, McpToolCatalog
from .computer_use import ComputerUseAdapter

logger = logging.getLogger(__name__)


@dataclass
class TaskResult:
    """任务执行结果"""
    task_id: str
    has_task: bool = False
    task_description: str = ""
    execution_method: str = "none"  # "mcp" | "computer_use" | "none"
    success: bool = False
    result: Any = None
    error: Optional[str] = None
    tool_name: Optional[str] = None
    tool_args: Optional[Dict] = None
    reason: str = ""


@dataclass
class McpDecision:
    """MCP 可行性评估结果"""
    has_task: bool = False
    can_execute: bool = False
    task_description: str = ""
    tool_name: Optional[str] = None
    tool_args: Optional[Dict] = None
    reason: str = ""


@dataclass
class ComputerUseDecision:
    """ComputerUse 可行性评估结果"""
    has_task: bool = False
    can_execute: bool = False
    task_description: str = ""
    reason: str = ""


class DirectTaskExecutor:
    """
    直接任务执行器：并行评估 MCP、UserPlugin 与 ComputerUse 可行性
    
    流程:
    1. 并行调用多个评估器：_assess_mcp、_assess_user_plugin、_assess_computer_use
    2. 优先使用 MCP（如果可行），其次 UserPlugin，再次 ComputerUse（优先级可调整）
    3. 执行选中的方法
    """
    
    def __init__(self, computer_use: Optional[ComputerUseAdapter] = None):
        self.router = McpRouterClient()
        self.catalog = McpToolCatalog(self.router)
        self.computer_use = computer_use or ComputerUseAdapter()
        self._config_manager = get_config_manager()
        self.plugin_list = []
        self.user_plugin_enabled_default = False
    
    
    async def plugin_list_provider(self, force_refresh: bool = True) -> List[Dict[str, Any]]:
        if (self.plugin_list == []) or force_refresh:
            try:
                url = f"http://localhost:{USER_PLUGIN_SERVER_PORT}/plugins"
                # increase timeout and avoid awaiting a non-awaitable .json()
                timeout = httpx.Timeout(5.0, connect=2.0)
                async with httpx.AsyncClient(timeout=timeout) as _client:
                    resp = await _client.get(url)
                    try:
                        data = resp.json()
                    except Exception:
                        # fallback to text parse
                        try:
                            data = json.loads(await resp.aread())
                        except Exception:
                            data = {}
                    plugin_list = data.get("plugins", []) if isinstance(data, dict) else (data if isinstance(data, list) else [])
                    # only update cache when we obtained a non-empty list
                    if plugin_list:
                        self.plugin_list = plugin_list  # 更新实例变量
            except Exception as e:
                logger.warning(f"[Agent] plugin_list_provider http fetch failed: {e}")
        logger.info(self.plugin_list)
        return self.plugin_list


    def _get_client(self):
        """动态获取 OpenAI 客户端"""
        core_config = self._config_manager.get_core_config()
        return AsyncOpenAI(
            api_key=core_config['OPENROUTER_API_KEY'],
            base_url=core_config['OPENROUTER_URL']
        )
    
    def _get_model(self):
        """获取模型名称"""
        core_config = self._config_manager.get_core_config()
        return core_config['SUMMARY_MODEL']
    
    def _format_messages(self, messages: List[Dict[str, str]]) -> str:
        """格式化对话消息"""
        lines = []
        for m in messages[-10:]:  # 最多取最近10条
            role = m.get('role', 'user')
            text = m.get('text', '')
            if text:
                lines.append(f"{role}: {text}")
        return "\n".join(lines)
    
    def _format_tools(self, capabilities: Dict[str, Dict[str, Any]]) -> str:
        """格式化工具列表供 LLM 参考"""
        if not capabilities:
            return "No MCP tools available."
        
        lines = []
        for tool_name, info in capabilities.items():
            desc = info.get('description', 'No description')
            schema = info.get('input_schema', {})
            params = schema.get('properties', {})
            required = schema.get('required', [])
            param_desc = []
            for p_name, p_info in params.items():
                p_type = p_info.get('type', 'any')
                is_required = '(required)' if p_name in required else '(optional)'
                param_desc.append(f"    - {p_name}: {p_type} {is_required}")
            
            lines.append(f"- {tool_name}: {desc}")
            if param_desc:
                lines.extend(param_desc)
        
        return "\n".join(lines)
    
    async def _assess_mcp(
        self, 
        conversation: str, 
        capabilities: Dict[str, Dict[str, Any]]
    ) -> McpDecision:
        """
        独立评估 MCP 可行性（专注于 MCP 工具）
        """
        if not capabilities:
            return McpDecision(has_task=False, can_execute=False, reason="No MCP tools available")
        
        tools_desc = self._format_tools(capabilities)
        
        system_prompt = f"""You are an MCP tool selection agent. Your ONLY job is to determine if the user's request can be handled by the available MCP tools.

AVAILABLE MCP TOOLS:
{tools_desc}

INSTRUCTIONS:
1. Analyze if the conversation contains an actionable task request
2. If yes, determine if ANY of the available MCP tools can handle it
3. If a tool can handle it, provide the exact tool name and arguments
4. Be precise with the tool arguments - they must match the tool's schema

OUTPUT FORMAT (strict JSON):
{{
    "has_task": boolean,
    "can_execute": boolean,
    "task_description": "brief description of the task",
    "tool_name": "exact_tool_name or null",
    "tool_args": {{...}} or null,
    "reason": "why this decision"
}}"""

        user_prompt = f"Conversation:\n{conversation}"
        
        # Retry策略：重试2次，间隔1秒、2秒
        max_retries = 3
        retry_delays = [1, 2]
        
        for attempt in range(max_retries):
            try:
                client = self._get_client()
                model = self._get_model()
                
                request_params = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0,
                    "max_tokens": 600
                }
                
                if model in MODELS_WITH_EXTRA_BODY:
                    request_params["extra_body"] = {"enable_thinking": False}
                
                response = await client.chat.completions.create(**request_params)
                text = response.choices[0].message.content.strip()
                
                logger.debug(f"[MCP Assessment] Raw response: {text[:200]}...")
                
                # 解析 JSON
                if text.startswith("```"):
                    text = text.replace("```json", "").replace("```", "").strip()
                decision = json.loads(text)
                
                return McpDecision(
                    has_task=decision.get('has_task', False),
                    can_execute=decision.get('can_execute', False),
                    task_description=decision.get('task_description', ''),
                    tool_name=decision.get('tool_name'),
                    tool_args=decision.get('tool_args'),
                    reason=decision.get('reason', '')
                )
                
            except (APIConnectionError, InternalServerError, RateLimitError) as e:
                if attempt < max_retries - 1:
                    wait_time = retry_delays[attempt]
                    logger.warning(f"[MCP Assessment] 调用失败 (尝试 {attempt + 1}/{max_retries})，{wait_time}秒后重试: {e}")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"[MCP Assessment] Failed after {max_retries} attempts: {e}")
                    return McpDecision(has_task=False, can_execute=False, reason=f"Assessment error after {max_retries} attempts: {e}")
            except Exception as e:
                logger.error(f"[MCP Assessment] Failed: {e}")
                return McpDecision(has_task=False, can_execute=False, reason=f"Assessment error: {e}")
    
    async def _assess_computer_use(
        self, 
        conversation: str,
        cu_available: bool
    ) -> ComputerUseDecision:
        """
        独立评估 ComputerUse 可行性（专注于 GUI 操作）
        """
        if not cu_available:
            return ComputerUseDecision(
                has_task=False, 
                can_execute=False, 
                reason="ComputerUse not available"
            )
        
        system_prompt = """You are a GUI automation assessment agent. Your ONLY job is to determine if the user's request requires GUI/desktop automation.

GUI AUTOMATION CAPABILITIES:
- Control mouse (click, move, drag)
- Control keyboard (type, hotkeys)
- Open/close applications
- Browse the web
- Interact with Windows UI elements

INSTRUCTIONS:
1. Analyze if the conversation contains an actionable task request
2. Determine if the task REQUIRES GUI interaction (e.g., opening apps, clicking buttons, web browsing)
3. Tasks like "open Chrome", "click on X", "type something" require GUI
4. Tasks that can be done via API/tools (file operations, data queries) do NOT need GUI

OUTPUT FORMAT (strict JSON):
{
    "has_task": boolean,
    "can_execute": boolean,
    "task_description": "brief description of the task",
    "reason": "why this decision"
}"""

        user_prompt = f"Conversation:\n{conversation}"
        
        # Retry策略：重试2次，间隔1秒、2秒
        max_retries = 3
        retry_delays = [1, 2]
        
        for attempt in range(max_retries):
            try:
                client = self._get_client()
                model = self._get_model()
                
                request_params = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0,
                    "max_tokens": 400
                }
                
                if model in MODELS_WITH_EXTRA_BODY:
                    request_params["extra_body"] = {"enable_thinking": False}
                
                response = await client.chat.completions.create(**request_params)
                text = response.choices[0].message.content.strip()
                
                logger.debug(f"[ComputerUse Assessment] Raw response: {text[:200]}...")
                
                # 解析 JSON
                if text.startswith("```"):
                    text = text.replace("```json", "").replace("```", "").strip()
                decision = json.loads(text)
                
                return ComputerUseDecision(
                    has_task=decision.get('has_task', False),
                    can_execute=decision.get('can_execute', False),
                    task_description=decision.get('task_description', ''), 
                    reason=decision.get('reason', '')
                )
                
            except (APIConnectionError, InternalServerError, RateLimitError) as e:
                if attempt < max_retries - 1:
                    wait_time = retry_delays[attempt]
                    logger.warning(f"[ComputerUse Assessment] 调用失败 (尝试 {attempt + 1}/{max_retries})，{wait_time}秒后重试: {e}")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"[ComputerUse Assessment] Failed after {max_retries} attempts: {e}")
                    return ComputerUseDecision(has_task=False, can_execute=False, reason=f"Assessment error after {max_retries} attempts: {e}")
            except Exception as e:
                logger.error(f"[ComputerUse Assessment] Failed: {e}")
                return ComputerUseDecision(has_task=False, can_execute=False, reason=f"Assessment error: {e}")
    
    async def _assess_user_plugin(self, conversation: str, plugins: Any) -> Any:
        """
        评估本地用户插件可行性（plugins 为外部传入的插件列表）
        返回结构与 MCP 决策类似，但包含 plugin_id/plugin_args
        """
        # 如果没有插件，快速返回
        try:
            if not plugins:
                return type("UP", (), {"has_task": False, "can_execute": False, "task_description":"", "plugin_id": None, "plugin_args": None, "reason":"No plugins"})
        except Exception:
            return type("UP", (), {"has_task": False, "can_execute": False, "task_description":"", "plugin_id": None, "plugin_args": None, "reason":"Invalid plugins"})
    
        # 构建插件描述供 LLM 参考（只包含 id, description, input_schema）
        lines = []
        try:
            # plugins can be dict or list
            iterable = plugins.items() if isinstance(plugins, dict) else enumerate(plugins)
            for _, p in iterable:
                pid = p.get("id") if isinstance(p, dict) else getattr(p, "id", None)
                desc = p.get("description", "") if isinstance(p, dict) else getattr(p, "description", "")
                schema = p.get("input_schema", {}) if isinstance(p, dict) else getattr(p, "input_schema", {})
                # Only include well-formed plugin entries
                if not pid:
                    continue
                try:
                    schema_str = json.dumps(schema)
                except Exception:
                    schema_str = "{}"
                lines.append(f"- {pid}: {desc} | schema: {schema_str}")
        except Exception:
            pass
        
        plugins_desc = "\n".join(lines) if lines else "No plugins available."
        # truncate to avoid overly large prompts
        if len(plugins_desc) > 2000:
            plugins_desc = plugins_desc[:2000] + "\n... (truncated)"
        logger.debug(f"[UserPlugin] passing plugin descriptions (truncated): {plugins_desc[:1000]}")
        
        # Provide a concrete JSON example to guide model outputs and reduce parsing errors
        example_json = json.dumps({
            "has_task": True,
            "can_execute": True,
            "task_description": "example: call testPlugin with a message",
            "plugin_id": "testPlugin",
            "plugin_args": {"message": "hello"}
        }, ensure_ascii=False)
        
        # Strongly enforce JSON-only output to reduce parsing errors
        system_prompt = f"""You are a User Plugin selection agent. AVAILABLE PLUGINS:
{plugins_desc}

INSTRUCTIONS:
1. Analyze the conversation and determine if any available plugin can handle the user's request.
2. If yes, return the plugin id and arguments matching the plugin's schema.
3. OUTPUT MUST BE ONLY a single JSON object and NOTHING ELSE. Do NOT include any explanatory text, markdown, or code fences.

EXAMPLE (must follow this structure exactly):
{example_json}

OUTPUT FORMAT:
{{
    "has_task": boolean,
    "can_execute": boolean,
    "task_description": "brief description",
    "plugin_id": "plugin id or null",
    "plugin_args": {{...}} or null,
    "reason": "why"
}}

VERY IMPORTANT: Return the JSON object only, with no surrounding text.
"""
        user_prompt = f"Conversation:\\n{conversation}\\n\\nUser intent (one-line): {conversation.splitlines()[-1] if conversation.splitlines() else ''}"
        
        max_retries = 3
        retry_delays = [1, 2]
        
        for attempt in range(max_retries):
            try:
                client = self._get_client()
                model = self._get_model()
                
                request_params = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    "temperature": 0,
                    "max_tokens": 400
                }
                
                if model in MODELS_WITH_EXTRA_BODY:
                    request_params["extra_body"] = {"enable_thinking": False}
                
                response = await client.chat.completions.create(**request_params)
                # Capture raw response and log prompts/response at INFO so it's visible in runtime logs
                try:
                    raw_text = response.choices[0].message.content
                except Exception:
                    raw_text = None
                # Log the prompts we sent (truncated) and the raw response (truncated) at INFO level
                try:
                    prompt_dump = (system_prompt + "\n\n" + user_prompt)[:2000]
                except Exception:
                    prompt_dump = "(failed to build prompt dump)"
                logger.info(f"[UserPlugin Assessment] prompt (truncated): {prompt_dump}")
                logger.info(f"[UserPlugin Assessment] raw LLM response: {repr(raw_text)[:2000]}")
                
                text = raw_text.strip() if isinstance(raw_text, str) else ""
                
                if text.startswith("```"):
                    text = text.replace("```json", "").replace("```", "").strip()
                
                # If the response is empty or not valid JSON, log and return a safe decision
                if not text:
                    logger.warning("[UserPlugin Assessment] Empty LLM response; cannot parse JSON")
                    return type("UP", (), {"has_task": False, "can_execute": False, "task_description": "", "plugin_id": None, "plugin_args": None, "reason": "Empty LLM response"})
                
                try:
                    decision = json.loads(text)
                except Exception as e:
                    logger.error(f"[UserPlugin Assessment] JSON parse error: {e}; raw_text (truncated): {repr(raw_text)[:2000]}")
                    return type("UP", (), {"has_task": False, "can_execute": False, "task_description": "", "plugin_id": None, "plugin_args": None, "reason": f"JSON parse error: {e}"})
                
                # return a simple object-like struct
                return type("UP", (), {
                    "has_task": decision.get("has_task", False),
                    "can_execute": decision.get("can_execute", False),
                    "task_description": decision.get("task_description", ""),
                    "plugin_id": decision.get("plugin_id"),
                    "plugin_args": decision.get("plugin_args"),
                    "reason": decision.get("reason", "")
                })
                
            except (APIConnectionError, InternalServerError, RateLimitError) as e:
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delays[attempt])
                else:
                    return type("UP", (), {"has_task": False, "can_execute": False, "reason": f"Assessment error: {e}"})
            except Exception as e:
                return type("UP", (), {"has_task": False, "can_execute": False, "reason": f"Assessment error: {e}"})
    
    async def analyze_and_execute(
        self, 
        messages: List[Dict[str, str]], 
        lanlan_name: Optional[str] = None,
        agent_flags: Optional[Dict[str, bool]] = None
    ) -> Optional[TaskResult]:
        """
        并行评估 MCP 和 ComputerUse，然后执行任务
        
        优先级: MCP > ComputerUse
        """
        import uuid
        task_id = str(uuid.uuid4())
        
        if agent_flags is None:
            agent_flags = {"mcp_enabled": False, "computer_use_enabled": False}
        
        mcp_enabled = agent_flags.get("mcp_enabled", False)
        computer_use_enabled = agent_flags.get("computer_use_enabled", False)
        user_plugin_enabled = agent_flags.get("user_plugin_enabled", False)
        
        # testUserPlugin: log entry with flags and short message summary for debugging
        try:
            msgs_summary = self._format_messages(messages)[:400].replace("\n", " ")
            logger.info(f"testUserPlugin: analyze_and_execute called task_id={task_id}, lanlan={lanlan_name}, agent_flags={agent_flags}, messages_summary='{msgs_summary}'")
        except Exception:
            logger.info(f"testUserPlugin: analyze_and_execute called task_id={task_id}, lanlan={lanlan_name}, agent_flags={agent_flags}")
        
        # 如果两个功能都没开启，直接返回
        if not mcp_enabled and not computer_use_enabled and not user_plugin_enabled:
            logger.debug("[TaskExecutor] Both MCP and ComputerUse disabled, skipping")
            return None
        
        # 格式化对话
        conversation = self._format_messages(messages)
        if not conversation.strip():
            return None
        
        # 准备并行评估任务
        assessment_tasks = []
        
        # MCP 评估任务
        capabilities = {}
        if mcp_enabled:
            try:
                capabilities = await self.catalog.get_capabilities(force_refresh=True)
                logger.info(f"[TaskExecutor] Found {len(capabilities)} MCP tools")
            except Exception as e:
                logger.warning(f"[TaskExecutor] Failed to get MCP capabilities: {e}")
        
        # ComputerUse 可用性检查
        cu_available = False
        if computer_use_enabled:
            try:
                cu_status = self.computer_use.is_available()
                cu_available = cu_status.get('ready', False)
                logger.info(f"[TaskExecutor] ComputerUse available: {cu_available}")
            except Exception as e:
                logger.warning(f"[TaskExecutor] Failed to check ComputerUse: {e}")
        
        # 并行执行评估（包含 user_plugin 分支）
        mcp_decision = None
        cu_decision = None
        up_decision = None
        
        if mcp_enabled and capabilities:
            assessment_tasks.append(('mcp', self._assess_mcp(conversation, capabilities)))
        
        # user plugin 支路（由外部 provider 提供插件列表）
        user_plugin_enabled = agent_flags.get("user_plugin_enabled", self.user_plugin_enabled_default)
        await self.plugin_list_provider()
        plugins = self.plugin_list
        
        if user_plugin_enabled and plugins:
            assessment_tasks.append(('up', self._assess_user_plugin(conversation, plugins)))
        
        if computer_use_enabled and cu_available:
            assessment_tasks.append(('cu', self._assess_computer_use(conversation, cu_available)))
        
        if not assessment_tasks:
            logger.debug("[TaskExecutor] No assessment tasks to run")
            return None
        
        # 并行执行所有评估
        logger.info(f"[TaskExecutor] Running {len(assessment_tasks)} assessments in parallel...")
        results = await asyncio.gather(*[task[1] for task in assessment_tasks], return_exceptions=True)
        
        # 收集结果（安全访问，先过滤异常）
        for i, (task_type, _) in enumerate(assessment_tasks):
            result = results[i]
            if isinstance(result, Exception):
                logger.error(f"[TaskExecutor] {task_type} assessment failed: {result}")
                continue
            # safe attribute access via getattr to avoid type issues
            if task_type == 'mcp':
                mcp_decision = result
                logger.info(f"[MCP] has_task={getattr(mcp_decision,'has_task',None)}, can_execute={getattr(mcp_decision,'can_execute',None)}, reason={getattr(mcp_decision,'reason',None)}")
            elif task_type == 'up':
                up_decision = result
                logger.info(f"[UserPlugin] has_task={getattr(up_decision,'has_task',None)}, can_execute={getattr(up_decision,'can_execute',None)}, reason={getattr(up_decision,'reason',None)}")
            elif task_type == 'cu':
                cu_decision = result
                logger.info(f"[ComputerUse] has_task={getattr(cu_decision,'has_task',None)}, can_execute={getattr(cu_decision,'can_execute',None)}, reason={getattr(cu_decision,'reason',None)}")
        
        # 决策逻辑：MCP 优先
        # 1. 如果 MCP 可以执行，使用 MCP
        if mcp_decision and mcp_decision.has_task and mcp_decision.can_execute:
            logger.info(f"[TaskExecutor] ✅ Using MCP: {mcp_decision.task_description}")
            result_obj = await self._execute_mcp(
                task_id=task_id,
                decision=mcp_decision
            )
            # Structured log of TaskResult (truncated)
            try:
                res_preview = str(result_obj.result) if result_obj.result is not None else ""
                if len(res_preview) > 800:
                    res_preview = res_preview[:800] + "...(truncated)"
                logger.info("TaskExecutor-OUT: %s", json.dumps({
                    "task_id": result_obj.task_id,
                    "execution_method": result_obj.execution_method,
                    "success": result_obj.success,
                    "reason": result_obj.reason,
                    "tool_name": result_obj.tool_name,
                    "tool_args": result_obj.tool_args,
                    "result_preview": res_preview
                }, ensure_ascii=False))
            except Exception:
                logger.info("TaskExecutor-OUT: (failed to serialize TaskResult)")
            return result_obj

        # 2. 如果 MCP 不行，但 ComputerUse 可以，返回 ComputerUse 任务
        if cu_decision and cu_decision.has_task and cu_decision.can_execute:
            logger.info(f"[TaskExecutor] ✅ Using ComputerUse: {cu_decision.task_description}")
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=cu_decision.task_description,
                execution_method='computer_use',
                success=False,  # 标记为待执行
                reason=cu_decision.reason
            )
        
        # 3. 如果 MCP 不行，但 UserPlugin 可用且可执行，优先调用 UserPlugin
        if up_decision and getattr(up_decision, "has_task", False) and getattr(up_decision, "can_execute", False):
            logger.info(f"[TaskExecutor] ✅ Using UserPlugin: {up_decision.task_description}, plugin_id={getattr(up_decision, 'plugin_id', None)}")
            try:
                return await self._execute_user_plugin(task_id=task_id, up_decision=up_decision)
            except Exception as e:
                logger.error(f"[TaskExecutor] UserPlugin execution failed: {e}")
                return TaskResult(
                    task_id=task_id,
                    has_task=True,
                    task_description=getattr(up_decision, "task_description", ""),
                    execution_method='user_plugin',
                    success=False,
                    error=str(e),
                    reason=getattr(up_decision, "reason", "") or "UserPlugin execution error"
                )
                
        # 3. 两者都不行
        reason_parts = []
        if mcp_decision:
            reason_parts.append(f"MCP: {mcp_decision.reason}")
        if cu_decision:
            reason_parts.append(f"ComputerUse: {cu_decision.reason}")
        
        # 检查是否有任务但无法执行
        has_any_task = (mcp_decision and mcp_decision.has_task) or (cu_decision and cu_decision.has_task)
        if has_any_task:
            task_desc = (mcp_decision.task_description if mcp_decision and mcp_decision.has_task 
                        else cu_decision.task_description if cu_decision else "")
            logger.info(f"[TaskExecutor] Task detected but cannot execute: {task_desc}")
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=task_desc,
                execution_method='none',
                success=False,
                reason=" | ".join(reason_parts) if reason_parts else "No suitable method"
            )
        
        # 没有检测到任务
        logger.debug("[TaskExecutor] No task detected")
        return None
    
    async def _execute_mcp(
        self, 
        task_id: str, 
        decision: McpDecision
    ) -> TaskResult:
        """执行 MCP 工具调用"""
        tool_name = decision.tool_name
        tool_args = decision.tool_args or {}
        
        if not tool_name:
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=decision.task_description,
                execution_method='mcp',
                success=False,
                error="No tool name provided",
                reason=decision.reason
            )
        
        logger.info(f"[TaskExecutor] Executing MCP tool: {tool_name} with args: {tool_args}")
        
        try:
            result = await self.router.call_tool(tool_name, tool_args)
            
            if result.get('success'):
                logger.info(f"[TaskExecutor] ✅ MCP tool {tool_name} succeeded")
                return TaskResult(
                    task_id=task_id,
                    has_task=True,
                    task_description=decision.task_description,
                    execution_method='mcp',
                    success=True,
                    result=result.get('result'),
                    tool_name=tool_name,
                    tool_args=tool_args,
                    reason=decision.reason
                )
            else:
                logger.error(f"[TaskExecutor] ❌ MCP tool {tool_name} failed: {result.get('error')}")
                return TaskResult(
                    task_id=task_id,
                    has_task=True,
                    task_description=decision.task_description,
                    execution_method='mcp',
                    success=False,
                    error=result.get('error', 'Tool execution failed'),
                    tool_name=tool_name,
                    tool_args=tool_args,
                    reason=decision.reason
                )
        except Exception as e:
            logger.error(f"[TaskExecutor] MCP tool execution error: {e}")
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=decision.task_description,
                execution_method='mcp',
                success=False,
                error=str(e),
                tool_name=tool_name,
                tool_args=tool_args,
                reason=decision.reason
            )
    
    async def _execute_user_plugin(self, task_id: str, up_decision: Any) -> TaskResult:
        """
        Execute a user plugin via HTTP endpoint.
        up_decision is expected to have attributes: plugin_id, plugin_args, task_description
        """
        plugin_id = getattr(up_decision, "plugin_id", None)
        plugin_args = getattr(up_decision, "plugin_args", {}) or {}
        task_description = getattr(up_decision, "task_description", "")
        
        if not plugin_id:
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=task_description,
                execution_method='user_plugin',
                success=False,
                error="No plugin_id provided",
                reason=getattr(up_decision, "reason", "")
            )
        

        
        # Ensure we have a plugins list to search (use cached self.plugin_list as fallback)
        try:
            plugins_list = self.plugin_list or []
        except Exception:
            plugins_list = []
        # If cache is empty, attempt to refresh once
        if not plugins_list:
            try:
                await self.plugin_list_provider(force_refresh=True)
                plugins_list = self.plugin_list or []
            except Exception:
                plugins_list = []
        
        # Find plugin entry in the resolved plugins list
        plugin_entry = None
        for p in plugins_list:
            try:
                if isinstance(p, dict) and p.get("id") == plugin_id:
                    plugin_entry = p
                    break
            except Exception:
                continue
        
        if plugin_entry is None:
            # Return a TaskResult indicating plugin not found instead of raising
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=task_description,
                execution_method='user_plugin',
                success=False,
                error=f"Plugin {plugin_id} not found",
                tool_name=plugin_id,
                tool_args=plugin_args,
                reason=getattr(up_decision, "reason", "") or "Plugin not found"
            )
        
        endpoint = plugin_entry.get("endpoint")
        if not endpoint:
            return TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=task_description,
                execution_method='user_plugin',
                success=False,
                error=f"Plugin {plugin_id} has no endpoint defined",
                tool_name=plugin_id,
                tool_args=plugin_args,
                reason=getattr(up_decision, "reason", "") or "No endpoint"
            )
        
        logger.info(f"[TaskExecutor] Calling user plugin {plugin_id} at {endpoint} with args: {plugin_args}")
        
        try:
            import httpx
            async with httpx.AsyncClient(timeout=5.0) as client:
                r = await client.post(endpoint, json={"task_id": task_id, "args": plugin_args})
                if r.status_code >= 200 and r.status_code < 300:
                    try:
                        data = r.json()
                    except Exception:
                        data = {"raw_text": r.text}
                    logger.info(f"[TaskExecutor] ✅ Plugin {plugin_id} returned success")
                    task_result = TaskResult(
                        task_id=task_id,
                        has_task=True,
                        task_description=task_description,
                        execution_method='user_plugin',
                        success=True,
                        result=data,
                        tool_name=plugin_id,
                        tool_args=plugin_args,
                        reason=getattr(up_decision, "reason", "")
                    )
                    # Structured log for TaskResult (user_plugin)
                    try:
                        res_preview = str(task_result.result) if task_result.result is not None else ""
                        if len(res_preview) > 800:
                            res_preview = res_preview[:800] + "...(truncated)"
                        logger.info("TaskExecutor-OUT: %s", json.dumps({
                            "task_id": task_result.task_id,
                            "execution_method": task_result.execution_method,
                            "success": task_result.success,
                            "reason": task_result.reason,
                            "tool_name": task_result.tool_name,
                            "tool_args": task_result.tool_args,
                            "result_preview": res_preview
                        }, ensure_ascii=False))
                    except Exception:
                        logger.info("TaskExecutor-OUT: (failed to serialize TaskResult for user_plugin)")
                    return task_result
                else:
                    text = r.text
                    logger.error(f"[TaskExecutor] ❌ Plugin {plugin_id} returned status {r.status_code}: {text}")
                    task_result = TaskResult(
                        task_id=task_id,
                        has_task=True,
                        task_description=task_description,
                        execution_method='user_plugin',
                        success=False,
                        error=f"Plugin returned status {r.status_code}",
                        result={"status_code": r.status_code, "text": r.text},
                        tool_name=plugin_id,
                        tool_args=plugin_args,
                        reason=getattr(up_decision, "reason", "")
                    )
                    try:
                        res_preview = str(task_result.result) if task_result.result is not None else ""
                        if len(res_preview) > 800:
                            res_preview = res_preview[:800] + "...(truncated)"
                        logger.info("TaskExecutor-OUT: %s", json.dumps({
                            "task_id": task_result.task_id,
                            "execution_method": task_result.execution_method,
                            "success": task_result.success,
                            "reason": task_result.reason,
                            "tool_name": task_result.tool_name,
                            "tool_args": task_result.tool_args,
                            "result_preview": res_preview
                        }, ensure_ascii=False))
                    except Exception:
                        logger.info("TaskExecutor-OUT: (failed to serialize TaskResult for user_plugin failure)")
                    return task_result
        except Exception as e:
            logger.error(f"[TaskExecutor] Plugin call error: {e}")
            task_result = TaskResult(
                task_id=task_id,
                has_task=True,
                task_description=task_description,
                execution_method='user_plugin',
                success=False,
                error=str(e),
                tool_name=plugin_id,
                tool_args=plugin_args,
                reason=getattr(up_decision, "reason", "")
            )
            try:
                res_preview = str(task_result.result) if task_result.result is not None else ""
                if len(res_preview) > 800:
                    res_preview = res_preview[:800] + "...(truncated)"
                logger.info("TaskExecutor-OUT: %s", json.dumps({
                    "task_id": task_result.task_id,
                    "execution_method": task_result.execution_method,
                    "success": task_result.success,
                    "reason": task_result.reason,
                    "tool_name": task_result.tool_name,
                    "tool_args": task_result.tool_args,
                    "result_preview": res_preview
                }, ensure_ascii=False))
            except Exception:
                logger.info("TaskExecutor-OUT: (failed to serialize TaskResult for plugin exception)")
            return task_result
    
    async def refresh_capabilities(self) -> Dict[str, Dict[str, Any]]:
        """刷新并返回 MCP 工具能力列表"""
        return await self.catalog.get_capabilities(force_refresh=True)
